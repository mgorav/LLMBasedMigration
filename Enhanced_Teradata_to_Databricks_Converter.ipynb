{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Teradata PL/SQL to Databricks Python Converter\n",
    "\n",
    "This notebook is designed to facilitate the conversion of a complex Teradata PL/SQL script, typically used in SAP data pipelines, into Python code that can be executed within a Databricks environment. The conversion process utilizes an open-source large language model for initial code generation, followed by manual refinements.\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bf44e577f0a7207"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Necessary Libraries\n",
    "We begin by importing essential Python libraries. `transformers` is used for accessing the language model, and `sqlparse` can optionally format SQL code for better readability.\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af677f1e93ae8f6f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "import sqlparse  # Optional for formatting SQL code\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:30:14.309866Z",
     "start_time": "2024-01-23T13:30:14.302193Z"
    }
   },
   "id": "ceceb24ac894dd7d",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize the Language Model\n",
    "Load an open-source model like GPT-Neo or GPT-J from Hugging Face's transformers library. These models serve as the foundation for our code conversion process.\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85bf74f66539ce3e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\r\n",
      "  Downloading torch-2.1.2-cp311-none-macosx_10_9_x86_64.whl (146.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m146.7/146.7 MB\u001B[0m \u001B[31m10.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: filelock in /Users/gauravmalhotra/lib/python3.11/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/gauravmalhotra/lib/python3.11/site-packages (from torch) (4.9.0)\r\n",
      "Collecting sympy (from torch)\r\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\r\n",
      "Collecting networkx (from torch)\r\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m35.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: jinja2 in /Users/gauravmalhotra/lib/python3.11/site-packages (from torch) (3.1.3)\r\n",
      "Requirement already satisfied: fsspec in /Users/gauravmalhotra/lib/python3.11/site-packages (from torch) (2023.12.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/gauravmalhotra/lib/python3.11/site-packages (from jinja2->torch) (2.1.4)\r\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\r\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "Installing collected packages: mpmath, sympy, networkx, torch\r\n",
      "Successfully installed mpmath-1.3.0 networkx-3.2.1 sympy-1.12 torch-2.1.2\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:32:44.525919Z",
     "start_time": "2024-01-23T13:32:13.799734Z"
    }
   },
   "id": "692188ec24ac4355",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:37:19.451074Z",
     "start_time": "2024-01-23T13:37:19.445736Z"
    }
   },
   "id": "396794f1c44e36be",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Hello, I am a language model, not a design model.\"\\n\\nBut how did your company get started?\\n\\nHolland, at 30 years old, says it started out looking a little outfitted with a software product development kit called'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Test the generator\n",
    "print(generator(\"Hello, I am a language model,\", max_length=50))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:39:07.883642Z",
     "start_time": "2024-01-23T13:38:54.923442Z"
    }
   },
   "id": "59d27a823727ef13",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Your Teradata PL/SQL Script\n",
    "Insert your complex Teradata PL/SQL script here. This script is used as the input for the conversion process. The example below is a placeholder, demonstrating typical PL/SQL constructs.\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb831160d3d0ae04"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Sample Teradata PL/SQL script (placeholder)\n",
    "teradata_plsql = \"\"\"\n",
    "CREATE PROCEDURE complex_procedure()\n",
    "BEGIN\n",
    "    DECLARE var_name VARCHAR(100);\n",
    "    SELECT column1 INTO var_name FROM table1 WHERE condition1;\n",
    "    IF var_name IS NOT NULL THEN\n",
    "        INSERT INTO table2(column2) VALUES(var_name);\n",
    "    ELSE\n",
    "        UPDATE table3 SET column3 = 'default' WHERE condition2;\n",
    "    END IF;\n",
    "    -- Further complex logic can be added here\n",
    "END;\n",
    "\"\"\"\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:39:33.271745Z",
     "start_time": "2024-01-23T13:39:33.266615Z"
    }
   },
   "id": "9567ff5cf8ff5e25",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert PL/SQL to Python for Databricks\n",
    "The following code converts the Teradata PL/SQL script to a Python script suitable for Databricks. This conversion uses PySpark, a standard tool in Databricks for large-scale data processing.\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd44c480d2fc7017"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert this Teradata PL/SQL script to a PySpark Python script for Databricks:\n",
      "\n",
      "\n",
      "CREATE PROCEDURE complex_procedure()\n",
      "BEGIN\n",
      "    DECLARE var_name VARCHAR(100);\n",
      "    SELECT column1 INTO var_name FROM table1 WHERE condition1;\n",
      "    IF var_name IS NOT NULL THEN\n",
      "        INSERT INTO table2(column2) VALUES(var_name);\n",
      "    ELSE\n",
      "        UPDATE table3 SET column3 = 'default' WHERE condition2;\n",
      "    END IF;\n",
      "    -- Further complex logic can be added here\n",
      "END;\n",
      "\n",
      "\n",
      "CREATE PROCEDURE 'python.py complex_procedure() \\\n",
      "\n",
      "*' sys.argv(2,4) ``''\n",
      "\n",
      "\n",
      "# Start by defining the Python interpreter from the command line;\n",
      "\n",
      "INI=''''\n",
      "\n",
      "\n",
      "CONVALL 'python.py complex_procedure'\n",
      "\n",
      "END PROCEDURE;\n",
      "\n",
      "\n",
      "END\n",
      "\n",
      "' -t simpleprocedure\n",
      "\n",
      "VARCHAR=2\n",
      "\n",
      "\n",
      "DATABASE my.file_types.py\n",
      "\n",
      "\n",
      "'pySpark::CREATE(int __varchar -1, __lenrow 8)-t my.file_types[8]:\n",
      "\n",
      "' PySpark (Python Script) This is a Python script that is used to run the Python interpreter\n",
      "\n",
      "from PySpark. Py_Spark.Run(' PySpark. pySpark ')\n",
      "\n",
      "PySpark.Init(my.python.py);\n",
      "\n",
      "...\n",
      "\n",
      "\n",
      "END\n",
      "\n",
      "\n",
      "EXEC\n",
      "\n",
      "\n",
      "' -t complexprocedure\n",
      "\n",
      "VARCHAR=2\n",
      "\n",
      "\n",
      "FUNCTION PySPARK()\n",
      "\n",
      "FUNCTION pySpark_parse()\n",
      "\n",
      "FUNCTION pySpark_run()\n",
      "\n",
      "FUNCTION pySpark_configure()\n",
      "\n",
      "FUNCTION pySpark_update()\n",
      "\n",
      "FUNCTION pySpark_checkload()\n",
      "\n",
      "FUNCTION pySpark_listen()\n",
      "\n",
      "FUNCTION pySpark_add_item()\n",
      "\n",
      "DATABASE PySPARK('pySpark-python.py')\n",
      "\n",
      "\n",
      "EXIT CREATE IF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Converting PL/SQL to Python for Databricks\n",
    "prompt = f\"Convert this Teradata PL/SQL script to a PySpark Python script for Databricks:\\n\\n{teradata_plsql}\\n\\n\"\n",
    "\n",
    "# Generate Python code\n",
    "python_code = generator(prompt, max_length=500)\n",
    "print(python_code[0]['generated_text'])\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:40:59.586003Z",
     "start_time": "2024-01-23T13:39:38.342177Z"
    }
   },
   "id": "f0c333849539ad6d",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please convert the following Teradata PL/SQL script into a PySpark Python script suitable for Databricks, and explain each step of the conversion:\n",
      "\n",
      "\n",
      "CREATE PROCEDURE complex_procedure()\n",
      "BEGIN\n",
      "    DECLARE var_name VARCHAR(100);\n",
      "    SELECT column1 INTO var_name FROM table1 WHERE condition1;\n",
      "    IF var_name IS NOT NULL THEN\n",
      "        INSERT INTO table2(column2) VALUES(var_name);\n",
      "    ELSE\n",
      "        UPDATE table3 SET column3 = 'default' WHERE condition2;\n",
      "    END IF;\n",
      "    -- Further complex logic can be added here\n",
      "END;\n",
      "\n",
      "\n",
      "The complex_procedure example of this project is quite similar to that for Python, except:\n",
      "\n",
      "DECLARE PROCESYSTEM('simpleprocedure'),\n",
      "\n",
      "USE PAPER.CREATE_STRATEGY;\n",
      "\n",
      "DECLARE PROCESYSTEM('database', 'SimpleProcedure');\n",
      "\n",
      "\n",
      "The following code runs the simpleprocedure application that creates tables on SQL Server 2012 R2.\n",
      "\n",
      "SELECT complex_procedure_name FROM table1;\n",
      "\n",
      "SET (\n",
      "\n",
      "SELECT var_name,\n",
      "\n",
      "CONTROL_SELECT,\n",
      "\n",
      "SELECT '1' FROM complex_procedure_name where SELECT condition1,\n",
      "\n",
      "SELECT '2' FROM complex_procedure_name AS SELECT conditions1\n",
      "\n",
      ",\n",
      "\n",
      "SELECT '3' FROM complex_procedure_name AS SELECT conditions2);\n",
      "\n",
      ");\n",
      "\n",
      "\n",
      "The following code retrieves a table that will be converted into a Python script based on the following data structures:\n",
      "\n",
      "VARCHAR(100) -> VALUES(0);\n",
      "\n",
      "VARCHAR(5066) -> VALUES(1);\n",
      "\n",
      "VARCHAR(4467) -> VALUES(2);\n",
      "\n",
      "VARCHAR(4464) -> VALUES(3);\n",
      "\n",
      "VARCHAR(4444) -> VALUES(4);\n",
      "\n",
      "\n",
      "The following Python script converts each of the complex_procedure tables to integers, which can then be used as input/output (the above example works on SQL 2010).\n",
      "\n",
      "#!/usr/bin/env python3\n",
      "\n",
      "FOR INSTR edX := '10' TO INStr edX + '30' AND edX >= 10;\n",
      "\n",
      "# the result is always between 10 and 30 and\n",
      "\n",
      "# '10' does not have any more rows\n",
      "\n",
      "for INSTR (x, y) DO\n",
      "\n",
      "{\n",
      "\n",
      "varchar(1) ->\n",
      "\n",
      "0\n",
      "\n",
      "}\n",
      "\n",
      "\n",
      "A number conversion is then done by adding an input to each of the 4 complex table functions (in these cases, the input value contains two decimal points in a row). The following Python script converts a 5+ integer into a 2+ integer from a binary.\n",
      "\n",
      "\n",
      "#!/usr/bin/env python\n",
      "\n",
      "for INSTR (0, 1) TO INStr (2, 3) WHEN NOT x\n",
      "\n",
      "{\n",
      "\n",
      "varchar(3) ->\n",
      "\n",
      "0\n",
      "\n",
      "}\n",
      "\n",
      "\n",
      "A binary conversion is then performed by first converting the 3 integer values into an 18, 1+ binary. The resulting integer is then converted to a 100 decimal point to produce the same binary as 5(2**26).\n",
      "\n",
      "\n",
      "The following program converts the complex tables into Python-converted values with the following formatting:\n",
      "\n",
      "for INSTR (1, 20) TO INStr (2, 19) DO\n",
      "\n",
      "{\n",
      "\n",
      "varchar(1) ->\n",
      "\n",
      "10\n",
      "\n",
      "}\n",
      "\n",
      "\n",
      "The following C code converts an integer to an 16.5-bit binary with the format given by\n",
      "\n",
      "{-# LANGUAGE Calculator #-}\n",
      "\n",
      "{-# LANGUAGE ConstraintFlags...\n",
      "\n",
      "}\n",
      "\n",
      "\n",
      "The following C code converts the complex tables into Python-converted values with the following formatting:\n",
      "\n",
      "for INSTR (1, 18) TO INStr (16, 1) DO\n",
      "\n",
      "{\n",
      "\n",
      "varchar(3) ->\n",
      "\n",
      "-64\n",
      "\n",
      "-128\n",
      "\n",
      "+16\n",
      "\n",
      "}\n",
      "\n",
      "Output:\n",
      "\n",
      "1210.0a 1111.50 aa6.3b10 0 10 10 10 1210.0a11 1111.50 aa6.3b10 1209.15 100 6 1210.0c02d 1 8 1 7.0b01b 1 7 8 10 16 15 1 1210.0c02d 10 1 1213.00b1b 12.5a10a 13 1 12\n"
     ]
    }
   ],
   "source": [
    "# Updated prompt asking for step-by-step explanation\n",
    "prompt = (f\"Please convert the following Teradata PL/SQL script into a PySpark Python script suitable for Databricks, \"\n",
    "          f\"and explain each step of the conversion:\\n\\n{teradata_plsql}\\n\\n\")\n",
    "\n",
    "# Generate Python code along with explanation\n",
    "python_code = generator(prompt, max_length=1000)  # Increased max_length for detailed explanation\n",
    "print(python_code[0]['generated_text'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:53:00.865773Z",
     "start_time": "2024-01-23T13:49:36.146972Z"
    }
   },
   "id": "1016804795c7743a",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d25b4b5d9d531256"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
